# `e8` vtables
1. Values are callable as AMD64 machine code
2. The initial instruction in any given value is probably `e8` to call the
   vtable, with the return address set to the instance data
3. Control flow is driven by objects
4. Garbage collection is also driven by objects (i.e. it's a hosted process)

## Method calls
Methods are numeric, assigned by protocol objects. They should refer into
indexed slots in vtables, and the method to be invoked should be stored in a
register, e.g. `%rax`.

**NB:** if objects are pointed to directly, we can't do complex object
addressing, e.g. records within columnar data structures. The records need to at
least provide the `e8 disp32` five-byte prefix and be addressible.

We may be able to get around this using pointer tagging to indicate that some
dereferencing is required. It also may just be a lost cause: suppose we've got
tagged pointers that refer to single bytes within some data structure; how do we
get from there to the hosting object without doing some kind of memory
alignment (which would be terrible)? Let's table this for now.

Back to method calls ... here's what I'm thinking:

```
              return address from e8 (on the return stack)
              |
              V
  e8 <vtable> instance-data ....
      |
      V
      48b9 <methodlist-address>         # %rcx = &methodlist
      488b o014o310                     # %rcx = *(%rcx + 8*%rax)
      ff o341                           # jmp *%rcx
```

Why encode the `e8` byte instead of just prefixing the object with the vtable
address? **No reason:** we can get the same type of polymorphism by having an
object store its own vtable and turning the `e8` into a nop: `e8 00000000`. Then
`e8` is implied and our overhead is down to 4 bytes, likely expanded to the
absolute 8 to keep everything simple. (Or we can limit the heap to 1GB.)

## Garbage collection
I think we can do this with a single method, `mark(heap)`, which does three
things:

1. Allocates space for the current object in the specified heap
2. Marks the current object as having been GC-visited (i.e. its vtable is
   modified to a "moved object" object, and we store the new address)
3. Calls `mark()` on all objects we point to

GC can happen at any point, which means the stack may be arbitrarily deep; we
need to make sure things like long lists don't overflow it. We know that the
stack depth is limited by the live set size, but we don't have much beyond that.
I suppose we can reserve 3x the heap size: 1x for the old heap, 1x for the new
heap, and 1x for the GC stack (which is distinct from the regular stack).

## Stacks as data structures
If we're going to have the garbage collector trace the call stack, we need it to
be a data structure. This means we need to push some linkage markers that make
it callable. (This is a case where using the bare 8-byte vtable prefix is
crucial.)

**Q:** what is our stack setup? Do we trace the return stack at all? How would
we translate addresses if we're garbage-collecting vtables -- would we end up
with something like permgen? (I think we would.)

OK, we have blocks of code, like `progn` segments basically, that can call into
other things which then have continuations. How do we refer to that continuation
in an object sense? It's not a distinct object, it's an annotated pointer.

...let's use the extra space in `%rax` for annotations: there's _no way_ we'll
have more than 24 bits of methods. So that gives us 40 bits of extra element
addressing.

## Continuations and the calling convention
We need to be able to quote continuations, so the interpreter should itself be
an object that refers to immutable heap quantities. This means that
continuations are stacks, and that stacks are heap-allocated.

If we want the stack to be a managed object, then we'll need a lower-level
calling convention that objects use to invoke methods: you can't have
polymorphism without a monomorphic method invocation strategy.

We need monomorphism anyway: otherwise, how are our stack primitives
implemented? If the interpreter owns its stack objects, then it can encapsulate
polymorphism at that level -- so if we want to change the mechanism for those
structures, we instantiate a new interpreter with a different class.

Nope. Nope. Nope. This will never work. Interpreter steps need to be atomic; we
can't have a dangling dependency on some hosting return stack/etc. This means if
an interpreter backs into polymorphic structures to store its state, it's
because that interpreter is being emulated or it's managing its own ad-hoc
polymorphism.
