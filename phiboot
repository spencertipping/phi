#!/usr/bin/env perl

=head1 License
    phi programming language
    Copyright (C) 2018  Spencer Tipping

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU Affero General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU Affero General Public License for more details.

    You should have received a copy of the GNU Affero General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.


=head1 phi boot image generator
This script emits a Linux/AMD64 machine code image. We aren't linked to any
libraries (including libc), so everything bottoms out in terms of system calls
and we aren't at all portable to other POSIX systems. This is an OK place to
start the world; later on we can specify how to build a C+JIT system that
interfaces to system functions using the standard C calling convention. The
image can then port itself to this backend.

Not all backends are low-level; we just start there because it's conveniently
minimalistic. phi can also recompile itself to languages like Javascript,
Python, Ruby, Perl, OCaml, Java, etc, each of which provides some form of GC and
OOP. phi is set up to delegate to hosting facilities when they're available.
(Optimizing effectively for each backend is another story that I'll address
within the phi codegen libraries.)


=head2 How we're building this image
The simplest strategy is to start with Perl objects and then have each one mark
itself into the initial "heap", which in this case is just the ELF image.
Addresses are absolute and some references are circular, so there's a bit of
trickery involved to get the initial stuff set up correctly. Let's talk a little
about what our boot image is made of.

Ultimately we want to build up to a set of primitive machine code fragments that
can be strung together using C<cons> or other combination primitives, along with
a parser that puts them together by reading code from stdin. These fragments,
and really every piece of memory we allocate here, all need to be self-aware
objects because the garbage collector will likely end up relocating them. This
means they need vtables.

Ideally our image ends up being portable, meaning it can port itself to
different execution environments (some of which aren't AMD64 machine code). We
don't necessarily need each code fragment to specify each backend
implementation, but we do need some sort of semantic awareness at the fragment
level.

Basically, we need a FORTH that provides a Smalltalk-style object layer. Since
this requires garbage collection, we get a free promotion from FORTH to Joy --
but the internals still look a lot like stuff we'd do in FORTH.

A quick note about register assignments:

  %rsp = return stack pointer (grows downwards)
  %rsi = data stack pointer (grows downwards)
  %rdi = interpreter object (doesn't change much, except during GC)

I'll get into more detail about how this works later on, but the gist of it is
that these registers need to be preserved for things to work correctly.
=cut

package phi;

use v5.14;          # required for pack() endian modifiers, // operator
use strict;
use warnings;

use Carp;

BEGIN
{
  $Carp::Verbose = 1;
  $SIG{__DIE__} = sub { Carp::confess @_ };
}

no warnings 'void';


=head2 Object assembler
We could write the phi boot image in assembly language. The big advantage to
doing it in Perl is that we get better automation and finer control over the
exact machine instructions that get emitted. Both of these things matter a lot.

At a high level, here's what we need from an assembler interface:

1. Hex literal bytes
2. Octal literal bytes (mostly for ModR/M encoding)
3. Namespaced labels
4. Absolute positioning/addressing
5. C<pack> references to constants, relative labels, or absolute links

Everything ends up with an absolute address, so the linker can use the standard
two-pass design: allocate space first, then patch in the correct locations. We
don't have any addresses that change size, e.g. C<jmp label> in assembly; all of
the sizes are hard-coded up front and we do a quick overflow check to make sure
C<jmp short> (and other small-value) instructions are within range.


=head3 Authoring things
What we really need is something that behaves like a string but remains valid
(in the binary-linkage sense) even if we don't know the heap location of
everything up front. We should be able to insert C<pack> placeholders whose
values will later be computed, and we should also be able to easily grab a
pointer to any location within a string.

I think we want something like this:

  my $fn   = asm->c3;
  my $code = asm->e8pl($fn - right)->c3;

We first add everything to the heap; then once the addresses are set, the
objects can go back and patch themselves.
=cut


sub left();
sub right();
sub phi::asm();
sub phi::l($);


sub location_of
{
  my ($x, $asm) = @_;
  my $l = ref $x ? $x->location($asm) : $x;
  die "$x has no defined location" unless defined $l;
  $l;
}


package phi::asm
{
  # Shorthand: asm->... instead of phi::asm->new->...
  sub phi::asm() { phi::asm::->new }

  use overload qw/ 0+ ptr "" linked /;

  BEGIN { ++$INC{'phi/asm.pm'} }

  sub new
  {
    bless { template => [],
            args     => [],
            labels   => {},
            location => undef }, shift;
  }

  sub locate       { $_[0]->{location} = $_[1]; shift }
  sub location     { shift->{location} // die "unallocated asm object" }
  sub is_located   { defined shift->{location} }
  sub size         { length shift->unlinked }
  sub ptr          { phi::asm_ptr->new(shift) }
  sub rptr         { phi::asm_ptr->new($_[0], $_[0]->size, 1) }

  sub dependencies { grep ref, map @$_, @{shift->{args}} }
  sub unlinked     { shift->compile(sub { 0 }) }
  sub linked
  {
    my $self = shift;
    die "cannot link an unallocated asm object"
      unless $self->is_located or !$self->dependencies;
    $self->compile(sub { shift->location($self) });
  }

  sub link_at
  {
    # Link in this object and all unallocated dependencies (transitively),
    # returning a flat memory allocation.
    my ($self, $location) = @_;
    die "link_at: moving already-located object from "
      . "$$self{location} to $location"
      if $self->is_located && $self->location != $location;

    $self->locate($location);
    my $asm = phi::asm->locate($location);
    $location += $self->size;

    my @linked;

    push(@linked, $_ = $_->link_at($location)),
    $location += $_->size
      for grep !$_->is_located, $self->dependencies;

    $asm->lit($_->linked) for $self, @linked;
    $asm;
  }

  sub safe_pack
  {
    # Identical to pack(), but verifies that none of the numeric args has
    # overflowed. We detect this by unpacking to make sure we reconstruct the
    # original list.
    my ($template, @xs) = @_;
    my $packed = pack $template, @xs;
    my $xs = join", ", @xs;
    my $ys = join", ", unpack $template, $packed;
    lc $xs eq lc $ys or
      die "phi::asm: inconsistent reconstruction for $template: [$xs] vs [$ys]";

    $packed;
  }

  sub compile
  {
    my ($self, $resolver) = @_;
    join"", map safe_pack($$self{template}[$_], map ref ? $resolver->($_) : $_,
                                                    @{$$self{args}[$_]}),
                0..$#{$$self{template}};
  }

  sub rewrite_left_right { shift }
  sub rewrite_here
  {
    my $self  = shift;
    my $left  = shift;
    my $right = $self->rptr;
    map ref ? $_->rewrite_left_right($left, $right) : $_, @_;
  }

  sub append
  {
    my $self     = shift;
    my $template = shift;
    my $left     = $self->rptr;

    # First, stage the arguments so we can calculate the new unlinked size.
    push @{$$self{template}}, $template;
    push @{$$self{args}},     [@_];

    my @args = $self->rewrite_here($left, @_);

    # Now we have revised offsets for delta pointers, so replace the args we
    # just added with the rewritten ones.
    #
    # NB: this means you can't reliably refer to the RHS of things like
    # BER-encoeed integers, but that kinda makes sense.
    $$self{args}[-1] = \@args;
    $self;
  }

  sub hex { shift->append("H*", join"", @_) }
  sub oct { shift->append("C",  CORE::oct shift) }
  sub lit { shift->append("a*", shift) }

  sub label
  {
    my ($self, $name) = @_;
    die "redefining label $name" if exists $$self{labels}{$name};
    $$self{labels}{$name} = $self->rptr;
    $self;
  }

  sub resolve
  {
    my ($self, $label) = @_;
    $$self{labels}{$label} // die "undefined label $label";
  }

  # NB: we need to define this to prevent it from falling into AUTOLOAD
  sub DESTROY {}

  # Syntactic completion for a few types of methods depending on their pattern
  our $AUTOLOAD;
  sub AUTOLOAD
  {
    my $self   = shift;
    my $method = $AUTOLOAD =~ s/.*:://r;

    while (length $method)
    {
      next if $method =~ s/^_+//;

      $self->hex($1),        next if $method =~ s/^x?((?:[0-9a-fA-F]{2})+)//;
      $self->oct($1),        next if $method =~ s/^o([0-3][0-7]{2})//;
      $self->lit($method),   last if $method =~ s/^q//;
      $self->label($method), last if $method =~ s/^l//;

      # Direct pack templates: force little-endian on all native integer types,
      # use R as a shorthand for the / repeat specifier.
      $self->append($method =~ s/([slqiSLQI])/($1\<)/gr
                            =~ s/R/\//gr
                            =~ s/_//gr,
                    @_), last
        if $method =~ s/^p//;

      die "phi::asm: failed to parse method snippet starting with $method "
        . "(original call was \"$AUTOLOAD\")";
    }
    $self;
  }
}


package phi::asm_ptr
{
  use Scalar::Util qw/refaddr/;
  use overload qw/ +  plus
                   -  minus
                   0+ location /;

  BEGIN { ++$INC{'phi/asm_ptr.pm'} }

  sub new
  {
    my ($class, $base, $delta, $scale) = @_;
    bless { base  => $base,
            delta => $delta // 0,
            scale => $scale // 1 }, $class;
  }

  sub plus  { phi::asm_ptr->new(shift, shift,  1) }
  sub minus { phi::asm_ptr->new(shift, shift, -1) }

  sub rewrite
  {
    my ($x, $l, $r) = @_;
    return $x unless ref $x;
      refaddr $x eq refaddr phi::left  ? $l
    : refaddr $x eq refaddr phi::right ? $r
    : $x;
  }

  sub rewrite_left_right
  {
    my ($self, $l, $r) = @_;
    phi::asm_ptr->new(rewrite($$self{base},  $l, $r),
                      rewrite($$self{delta}, $l, $r),
                      $$self{scale});
  }

  sub is_located   { not grep !$_->is_located, shift->dependencies }
  sub dependencies { grep ref, @{+shift}{'base', 'delta'} }
  sub link_at
  {
    my ($self, $l) = @_;
    my $asm = $$self{base}->link_at($l);
    $asm->lit($$self{delta}->link_at($asm->rptr->location)->linked)
      if ref $$self{delta};
    $asm;
  }

  sub location
  {
    my ($self, $asm) = @_;
    phi::location_of($$self{base}, $asm)
      + $$self{scale} * phi::location_of($$self{delta}, $asm);
  }
}


package phi::asm_label
{
  # Shorthand: l"name" to refer to a label
  sub phi::l($) { phi::asm_label->new(shift) }

  use parent 'phi::asm_ptr';

  BEGIN { ++$INC{'phi/asm_label.pm'} }

  sub new
  {
    my ($class, $name) = @_;
    bless \$name, $class;
  }

  sub rewrite_left_right { shift }

  sub link_at      { phi::asm }
  sub dependencies { () }
  sub is_located   { 1 }
  sub location
  {
    my ($self, $asm) = @_;
    phi::location_of $asm->resolve($$self), $asm;
  }
}


# Magic references that will be rewritten (NB: bless into the class only once
# the class is defined; otherwise we may run into problems with operator
# overloading due to a perl magic-caching bug -- I forget which version fixed
# this).
#
# More specifically, "left" and "right" refer to the bounds of the current pack
# template expression. These are used to emit relative jumps, for example.
use constant left  => bless \(my $x = "left"),  'phi::asm_ptr';
use constant right => bless \(my $x = "right"), 'phi::asm_ptr';


=head2 Base vtables
We'll have object wrappers around vtables later on, but we need to be able to
refer to them now so we can write precompiled objects.
=cut

use constant vtable_vtable     => asm;
use constant symbol_vtable     => asm;
use constant amd64_code_vtable => asm;

our %symbols;
sub symbol($) { $symbols{$_[0]} //= asm->pQ(symbol_vtable)->pvRa(shift) }


=head3 Primitives
These are very simple functions implemented as code structs. Most of the work
happens inside C<ucode> (short for "unlinked code"), which returns an assembler
for a code fragment object with a "code" label pointing to the jump target. You
need to label the end after dropping code in; otherwise the structs won't be
able to calculate their sizes.

Here's the struct layout for machine code fragments:

  vtable*:  8 bytes
  source*:  8 bytes
  nlinks:   2 bytes
  codesize: 2 bytes
  links:    3*nlinks bytes
  here:     2 bytes
  code:     codesize bytes

WARNING: every primitive function will blow away your registers. This is by
design: registers can't contribute values to the live set for GC purposes
because those values wouldn't be tagged, so we have to make a promise that
anytime memory is allocated onto the heap (possibly triggering the GC), our
registers are all fully committed into GC-readable structures like the data
stack. Basically, once you start using these, you're committing to living in
concatenative-world, not machine code world.
=cut

sub ucode($)
{
  my $source_symbol = shift;
  asm->pQQ(amd64_code_vtable,
           symbol $source_symbol)
     ->pS(0)
     ->pS(l("end") - l("code"))
     ->_                                # no links
     ->here
     ->lcode;
}


=head2 Threading
L<https://en.wikipedia.org/wiki/Threaded_code>, as opposed to multithreading.

phi is _sort of_ threaded by nature. Method calls are subroutine calls once the
method is specified and virtual stuff is resolved, so we end up in more or less
the same place. Because I'm not as familiar with this as I need to be, let's go
through some existing threading models.


=head3 Call threading
The obvious one: just emit a bunch of e8 C<call> instructions, each with a
relative address:

  e8 fn1
  e8 fn2
  ...
  e8 fnN
  c3

20% larger than it needs to be, and relative addressing limits the heap
size/layout on 64-bit systems. The second problem can be fixed with the
absolute-address variant:

  48b8 fn1-absolute ffd0
  48b8 fn2-absolute ffd0
  ...
  48b8 fnN-absolute ffd0
  c3

Simple, linkable, difficult to inspect (unless you love the idea of parsing
machine code), fast, space-inefficient, and clunky as hell.


=head3 Direct threading
A list of addresses rather than the instructions to do the jumping. Then we'd
have an interpreter to do the instruction loop:

  fn1-absolute ---> machine code
  fn2-absolute ---> machine code
  ...
  fnN-absolute ---> machine code
  exit-absolute --> machine code    # not a marker; sentinels create overhead

The loop would then do something like C<lodsq; call *%rax>.

Direct threading is simple, linkable, compact, almost as fast as call threading
(faster if we get better icache usage), and easy to inspect.


=head3 Indirect threading
Basically, direct threading with codewords -- which is how Jonesforth works and
adds an element of polymorphism to code segments. This is quite clever and isn't
entirely unlike OOP:

  fn1-absolute ---> interpreter [code|data...]
  fn2-absolute ---> interpteter [code|data...]
  ...
  exit-absolute --> interpreter [code|data...]

The cool thing here is that each C<fnI> can be either native or itself threaded;
the "interpreter" sets up whatever is required to run each thing (which, for
native subroutines, just involves jumping directly into the machine code).

Technically indirect and direct threading are the same thing; the indirection is
just a pattern/hack you can use to get threaded subroutines to work as native
code. Either way, it's pretty cool -- and fast enough as long as subroutines
aren't too short.


=head3 Object-oriented code and threading
FORTH is functional (sort of) rather than object-oriented; as a result,
"objects" are either code or data. That is, you can run a function or inspect
it, but it doesn't _do_ anything other than running itself. Functions aren't
self-aware because they aren't objects in the Smalltalk sense: "do the thing"
isn't the same as "describe how you would do the thing."

If we want self-awareness, then, we need a new variable that indicates our
intent. I've been calling this the method index and assuming that we have
compact vtables with numbered methods. So in an indirect threading sense, we'd
end up with something like this:

  obj1-absolute ---> vtable [stuff]     # NB: completely broken; see below
  obj2-absolute ---> vtable [stuff]
  ...
  ???     # not sure about this yet

But we have a new problem: we aren't necessarily invoking the same method on
every object. For example, if had an object that was a key/value pair and we
wanted to know its size, our concatenative OOP code might look something like
this:

  .size = [ dup  .key   .size
            swap .value .size .+ ]

Although the calls to C<.key> and C<.value> are clearly monomorphic (since we
compiled the vtable for the receiver as a fully-resolved thing), C<.size> and
C<.+> are not. Also, C<dup> and C<swap> aren't method calls; they're just
regular functions. What do we do with this?

First things first: let's unify the instruction set a little. There's a handful
of primitives like C<dup> and C<swap>; then we have virtual method calls. I'm
not yet convinced there's a huge performance advantage to pre-resolving static
method calls, provided our vtable overhead is small enough (which I think it's
likely to be).

Our instruction set could be a simple list of small integers with optional
followers if we need extra data. For example:

  0 = dup
  1 = swap
  ...
  32-127: one-byte method call -- subtract 32
  128-255: two-byte method call -- subtract 32, add (next byte << 7)

We could save the subtraction by rearranging a bit:

  0-95: one-byte method call
  96-127: primitive instructions
  128-255: two-byte method call -- subtract 32, add (next byte << 7)

We can implement indirect threading, so method implementations are machine code
that is either native, or that sets up a trivial bytecode interpreter. This
leaves the door open for new instructions implemented as method calls against
the interpreter object even if we run out of primitive namespace.

So far so good, but we're not out of the woods yet. First, how do we encode
primitive types like numbers? Second, our return stack is going to include
pointers to the middle of these instruction blocks, but we still need to be able
to mark them for GC.


=head3 GC-marking threaded code
Any type of threaded code -- or really, anytime we use polymorphic machine code
objects -- is going to have this problem. Basically, let's suppose we have any
list with multiple method calls in it:

  [ .keys .size .negate ]

Internally let's say these are all one-byte method calls, so we'd have something
like this:

  [ 17 4 8 ]

Any of these methods could be arbitrarily complicated, of course, so at some
point we're going to end up pushing our continuation onto the return stack. If
we're evaluating C<.keys>:

       we want a pointer to this
       |
       V
  [ 17 4 8 ]

We can point to that byte, but the garbage collector will have no way of
understanding which object we're referring to. It doesn't have a lookup table of
objects and their sizes, and walking the heap to figure it out would be slow and
insane. Somehow we need to be able to go from "pointer to the middle of a thing"
to "pointer to the thing." C<here> pointers do that, but only if we're willing
to put a two-byte marker near every pointed-to location. For a bytecode like
this one that strategy would be incredibly wasteful.

=head4 Packed pointers
Our address space is 64 bits, which is 16 EiB -- far larger than we will ever be
able to use. Since the heap is contiguous, we can save some bits by referring to
relative offsets from the heap base; then our pointers can store additional
information. For example, if we decided to use 48 bits for the object address,
we could then use 16 to store the offset into a structure:

  0xaaaaaaaa_bbbbbbbb_cccccccc_00000000
  |
  |    0xdddddddd (relative to object base)
  |    |
  V    V
  [ 17 4 8 ]

That gives us an addressible range of 256 TiB. I don't love this because while
that sounds big at the moment, getting that much RAM in a single system is
certainly on the horizon and then we'll start hitting awkward limits. It also
eats a register and complicates heap dereferences slightly.

Now not every pointer needs to support compound referencing like this,
particularly given that pointers are themselves configurable (they have to be in
order to support full-width unboxed integers and floats).

Q: why constrain pointers to 64 bits at all? We could easily have 80-bit
pointers if we needed compound referencing. There's a case to be made for value
type polymorphism.

=head4 Polymorphic value types
Allocating a register for the heap base is actually quite useful. We can make
the rule that the currently-running interpreter is either the first allocation,
or directly behind the heap; then we get instruction and primitive polymorphism
with exactly one instruction of overhead. For example:

  | %rdi         | ioff             | vtoff
  interpreter... insns[ 0 ... 255 ] vtpoly[ 0 ... 255 ]

  # execute instruction in %rax
  call *(%rdi + %rax + ioff)

  # calculate vtable and object root for type tag %rax
  call *(%rdi + %rax + vtoff)

C<call> has a three-cycle reciprocal throughput on Broadwell, two-cycle on
Nehalem -- so it isn't free, but it is fairly cheap (~1ns).

=head4 Costs and benefits of polymorphic value types
Pros:

1. Unboxed ints _and_ floats in an accurate GC-able stack
2. Extensible pointer encodings
3. Extensible direct value encodings (e.g. short strings/symbols)
4. Direct struct returns, e.g. complex numbers

Cons:

1. Stack push/pop are no longer single instructions
2. Pointer dereferencing is no longer a single instruction
3. We have a limited number of slots, most likely just 256 (before cascading)

I'm not convinced we always have to pay the full cost of polymorphism. For
example, we'd need some type of stack tagging in any case just to support
unboxed int/float values; so generalizing out to an extensible setup isn't the
end of the world at all.

One thing I don't like is that the fixed number of slots means we're not truly
extensible; libraries can't just go and allocate value types without running a
serious risk of collision. That might not be a terrible thing for two reasons,
though: first, we can manage/cascade the dispatch if we need to; and second,
it's not at all clear to me that we'll need that many value types in the grand
scheme of things. Certainly it's worth having some customization potential given
that ints and floats get special treatment out of the gate.

=head4 Stack frame synthesis
Concatenative stuff is going to be slow if we're stepping through it: we do a
lot of unnecessary stack shuffling when ultimately it would be much more
efficient to emit frame-offset instructions against a frame pointer (e.g.
C<movq *(%rbp + disp), %rax>).

Polymorphic value types to the rescue, though! We can rewrite concatenative code
to use field accessors against a by-value struct type that we push onto the
stack, which essentially converts phi from a stack language into a register
language. The polymorphic value overhead amortizes to zero as our functions
increase in complexity (although this depends on our being able to make
non-virtual, and thus inlined, method calls against the stack frame object).

This is really nice. If functions can specify their types to some degree, then I
think we end up with a way to back OOP code straight into machine language, and
it should be about as efficient as native C (perhaps minus the processor
optimizations the compiler knows about).

Alright, polymorphic value types it is.

TODO: design these puppies


=head2 Concatenative instruction set
Alright, let's design the list of things we need to get this language off the
ground and fully concatenative. This is mostly low-level stuff because this
instruction set hosts everything, including garbage collection and its own
compilation.

Broadly speaking, we have a few categories of instructions:

1. Direct memory access
2. Stack manipulation
3. Interpreter interop (e.g. heap allocation)
4. Machine operations (e.g. int, float ops)
5. System operations (e.g. C<mmap>, C<read>)

Of these, (1) is only sometimes available and the API for (3) varies a little.
Let's talk about how.


=head3 Backend variants
We want to be able to run within different languages, the set of which spans
things like memory models, OOP/functional, and other paradigm differences. Some
cases like ASM.js involve bridging that gap within the same runtime. Because all
of this involves hard limits (we don't want to emulate a flat memory model if
the runtime provides GC for us), phi provides an operation that tells you about
the features available on the current runtime. Then you'll know which
instructions are enabled.

=head4 C<gc>
This is the biggest question mark for a runtime: how is memory managed? There
are a few options:

1. C<flat>: no GC; you have direct memory access (e.g. C, C++, machine code)
2. C<named>: no references/pointers (e.g. Perl4, POSIX sh, sed)
3. C<refcount>: cycles need to be broken, finalizers happen instantly (Perl5)
4. C<sync_tracing>: synchronous (pausing) mark/sweep (OCaml, Ruby?)
5. C<async_tracing>: concurrent mark/sweep (Java)

TODO: finalizer support?

=head4 C<int_size>
Basically, how big an int can we work with before overflowing a register? Sadly,
the number of bits is not always an even power of two; V8, OCaml, and Lisp each
use some form of bit tagging, reducing the effective integer precision to
slightly fewer than the native number of bits. On a 64-bit machine, this usually
means we get anywhere from 52 to 63 bits to work with (52 comes up if the
runtime pushes ints into NaN float values).

C<int_size> uses eight bits to encode the number of bits available in integers.

=head4 C<jit>
This setting can take on a few different values:

1. C<free>: there is no JIT overhead at all, e.g. machine code
2. C<fast>: you can quickly compile code at runtime, e.g. C<eval>
3. C<slow>: you can compile code via linkage, e.g. with the JVM; expect permgen
4. C<none>: you can't JIT anything; you'd have to restart the process


=head3 Direct memory access
Available only if C<gc == flat>.

1. C<< i64 addr >m64 >>: write i64 to memory
2. C<< addr <m64 : i64 >>: read i64 from memory, preserving tag
3. C<< i8 addr >m8 >>: write byte to memory
4. C<< addr <m8 : i8 >>: read byte from memory, push with int tag
5. C<< from to size <>m >>: copy byte range

We also need a couple of operators to get and set the type-tag on the top stack
entry.

6. C<< x <t = x.tag >>: get tag of top entry, as integer
7. C<< x t' >t = x' >>: set tag of top entry
=cut

# TODO


=head3 Stack manipulation
These functions are always available. Stack operators are the usual suspects,
minimized a bit:

1. C<< x     dup   = x x >>
2. C<< x     drop  = >>
3. C<< x y   swap  = y x >>
4. C<< x y   over  = x y x >>
5. C<< x y z rot3< = y z x >>
6. C<< n     pick  = stack[n] >>

Every stack operator runs in constant time. Depending on the backend, stack
operators may cause GC to happen; you should generate flattened code to avoid
this if you need allocation-free behavior.
=cut

# TODO


=head3 Interpreter operations
The interpreter is a regular phi object pointed to by C<%rdi>. Technically,
then, the only operator we need is one to push a reference to the interpreter.
Everything else can then be implemented using method calls.

There's a problem with this, though: how are those method calls implemented? For
example, how do we check for heap overflow and then kick off a GC? We need some
low-level operators to get and set the state of the machine registers we're
using to host the stacks. Those operators are:

1. C<< i' >i = >>: set the interpreter object
2. C<<    <i = i >>: get the interpreter object
3. C<< d' >d = >>: set the data stack pointer
4. C<<    <d = d >>: get the data stack pointer
5. C<< r' >r = >>: set the return stack pointer
6. C<<    <r = r >>: get the return stack pointer

The heap is owned by the interpreter and allocation happens as a method call
rather than using registers.

In order to use the interpreter, of course, we'll also need a numbered-method
invocation operator:

7. C<< obj n . = >>: invoke nth method on obj

This doubles as the eval operator for objects that support evaluation. C<eval>
is always method 0.

Let's talk about how method calls work, especially considering pointer tagging.

=head4 Method calling convention
As I mentioned above, pointers aren't monomorphic in phi: you could have an
object pointer, a here pointer, or a non-pointer like an int. It doesn't really
matter what we have as long as we can figure out what its vtable is. And that's
exactly what the tag represents: a vtable-resolution strategy -- or more
precisely, a method calling convention indicator.

There aren't very many different types of pointers -- just one byte's worth --
so we can use small offsets to implement them. Here's what the interpreter looks
like:

         8        16       24     32        36
  vtable | dstack | rstack | heap | tagsize | tag-ptrs[256] | code... | ...

Each C<tag-ptr> is an unsigned 16-bit value that encodes the jump offset from
the beginning of the interpreter object. Running that code will call a method on
a value with that tag. So our initial jump looks more or less like this:

  movbzx *%rsi, %rax                    # grab the tag
  movd *(%rdi + 2*%rax + 36), %ax       # get the code offset
  jmp *(%rdi + %rax)                    # tail-call into pointer/method delegate

The regular "pointer" delegate might then do this (Q: who puts the method index
into C<%rcx>?):

  movq *(%rsi + 1), %rax                # load the object
  movq *%rax, %rdx                      # load the vtable
  jmp *(%rdx + 8*%rcx)                  # tail-call method specified by %rcx

The "here" pointer delegate works this way:

  movq *(%rsi + 1), %rax                # load the object (hereptr)
  movwzx *(%rax - 2), %rdx              # load here-offset
  subq %rdx, %rax                       # adjust to get root object pointer
  movq *%rax, %rdx                      # get vtable
  jmp *(%rdx + 8*%rcx)                  # tail-call method

This looks heavy: at least six instructions for just a method call. TODO: how
bad is this?
=cut

# TODO


=head2 Instructions and lists
phi's compiler consumes instruction lists and produces machine code fragments.
This is a fairly straightforward process because phi is concatenative: for the
most part, C<compile([x y ...]) == compile([x]) ++ compile([y]) ++ ...>.

Neither instructions nor cons cells have any intrinsic awareness of how they
would be represented in any given backend. The purpose of cons cells and
instruction objects is strictly to _describe_ a computation, not specify how it
should happen.

We can evaluate (not just compile) a list by pushing all of the tail elements
onto the return stack and returning normally:

  [f1 f2 f3].eval() -> push $f3; push $f2; push $f1; ret

This is nice because it means we don't hold a reference to the list object even
while we're evaluating it.

We don't always have direct access to the return stack, for instance in most
hosted environments. In those cases we can just run a normal loop.
=cut

# TODO


=head2 Classes and protocols
In a world with only classes, we'd need to allocate a separate vtable index for
every single method, which would take up a lot of space:

  # the world without protocols: every class contains four vtable entries
  class A {
    method foo;     # vtable index 0
    method bar;     # vtable index 1
  }
  class B {
    method foo;     # vtable index 0
    _               # vtable index 1 is blank to avoid A::bar conflict
    method bif;     # vtable index 2
    method baz;     # vtable index 3
  }

This is equivalent to every class belonging to a single protocol that contains
the union of everyone's methods.

We can fix this by specifying which classes are eligible for which virtual
method calls, in this case by adding them to a protocol object:

  protocol has_foo {
    method foo;     # same vtable index within all member classes
  }
  class A : has_foo {
    method foo;     # vtable index 0
    method bar;     # vtable index 1
  }
  class B : has_foo {
    method foo;     # vtable index 0
    method bif;     # vtable index 1 (no collision with A::bar)
    method baz;     # vtable index 2
  }

This is basically how method resolution works in statically-typed languages like
Java or C++; phi also uses static typing when it comes to classes/methods, it
just has more support for runtime code generation.

Every virtual method invocation, then, addresses a protocol rather than a class.
Any class-focused method invocations are static function calls and are likely to
be inlined during compilation.

NB: we can't modify vtables once they're allocated, so compiled classes,
vtables, and dynamic method calls are all immutable once you start using them.
It's theoretically possible to enumerate heap objects and rewrite their vtables
if all you're doing is adding new methods to things, but that's a library thing
instead of something built into the object system.
=cut

# TODO: implement stuff


=head2 Build the image
This is pretty simple: we just write the entire heap contents into a file and
call it a day. This works because the heap begins with ELF header allocations
that locate it properly in memory.


=head3 Debugging code
Let's write some macros to make life much much easier. Basically, we want to
have some things we can drop into machine code to tell us what's going on inside
the image. We don't have libc, so int->string and such are functions we'll have
to write for ourselves if we want them.
=cut

sub phi::asm::exit_constant
{
  shift->_4831o300_b03c         # %rax = 0x3c (exit syscall)
       ->_48c7o307_pl(shift)    # %rdi = $code (exit code)
       ->_0f05;                 # syscall -- no return from here
}

sub phi::asm::debug_print
{
  my ($asm, $message, $fd) = @_;
  $fd //= 1;
  $asm->_50_52_56_57            # push %rax, %rdx, %rsi, %rdi
      ->_4831o300_b001          # %rax (n) = 1 (write syscall)
      ->_e8pl(length $message)  # call sizeof(message)
      ->lit($message)           # the message
      ->_5e                     # pop &message -> %rsi (buf)
      ->_bapl(length $message)  # mov length -> %rdx (len)
      ->_48c7o307pl($fd)        # %rdi (fd) = $fd
      ->_0f05                   # syscall
      ->_5f_5e_5a_58;           # pop %rdi, %rsi, %rdx, %rax
}

use constant entry_point => asm
  ->debug_print("image is ok\n")
  ->exit_constant(0);


=head3 ELF header
These behave like heap allocations because of page alignment. Basically, let's
say our virtual address space starts at 0x400000; because the ELF file is
memory-mapped rather than copied, we have the constraint that we can "move" the
file's contents only by increments of 4096 bytes -- whole pages. We can't assign
an arbitrary offset, e.g. to skip the ELF header.

This isn't much of a problem really. As far as phi is concerned, our initial
heap is maybe 120 bytes smaller than it would normally be because it's got some
mystery data (the ELF headers) prepended; then that will get garbage collected
because nothing refers into it. So the net impact of our ELF headers ends up
being zero, exactly what we want.
=cut

use constant elf_startaddr => 0x400000;
use constant elf_hdr       => asm
  ->pC16_SSL(
    0x7f, ord 'E', ord 'L', ord 'F',
    2, 1, 1, 0,
    0, 0, 0, 0,
    0, 0, 0, 0,

    2,                                  # e_type    = ET_EXEC
    62,                                 # e_machine = EM_X86_64
    1)                                  # e_version = EV_CURRENT
  ->pQ(entry_point)
  ->pQQ_LSS_SSSS(
    64,                                 # e_phoff
    0,                                  # e_shoff
    0,                                  # e_flags

    64,                                 # e_ehsize
    56,                                 # e_phentsize
    1,                                  # e_phnum

    0,                                  # e_shentsize
    0,                                  # e_shnum
    0)                                  # e_shstrndx
  ->pLLQQQQQQ(
    1,                                  # p_type = PT_LOAD
    7,                                  # p_flags = R|W|X (important)
    0,                                  # p_offset (must be page-aligned)
    elf_startaddr,                      # p_vaddr
    0,                                  # p_paddr
    0x1000,                             # p_filesz
    0x1000,                             # p_memsz
    0x1000);                            # p_align


=head3 Heap construction
Allocate everything into the heap, dependencies last. C<elf_hdr> must be the
first object we allocate in order to generate a valid executable.
=cut

caller or print elf_hdr->link_at(elf_startaddr)->linked;
