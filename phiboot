#!/usr/bin/env perl

=head1 License
    phi programming language
    Copyright (C) 2018  Spencer Tipping

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU Affero General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU Affero General Public License for more details.

    You should have received a copy of the GNU Affero General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.


=head1 phi boot image generator
This script emits a Linux/AMD64 machine code image. We aren't linked to any
libraries (including libc), so everything bottoms out in terms of system calls
and we aren't at all portable to other POSIX systems. This is an OK place to
start the world; later on we can specify how to build a C+JIT system that
interfaces to system functions using the standard C calling convention. The
image can then port itself to this backend.

Not all backends are low-level; we just start there because it's conveniently
minimalistic. phi can also recompile itself to languages like Javascript,
Python, Ruby, Perl, OCaml, Java, etc, each of which provides some form of GC
and/or OOP. phi is set up to delegate to hosting facilities when they're
available. (Optimizing effectively for each backend is another story that I'll
address within the phi codegen libraries.)
=cut

package phi;

use v5.14;          # required for pack() endian modifiers, // operator
use strict;
use warnings;
no warnings 'void';

use Carp;

BEGIN
{
  $Carp::Verbose = 1;
  $SIG{__DIE__} = sub { Carp::confess @_ };
}


=head2 General build/debug settings
We want to be able to inspect various aspects of phi's behavior quickly, so I've
built in a bunch of conditional build settings that compile debug tracers into
the image if we need them.
=cut

use constant DEBUG_TRACE_INSNS  => 0;
use constant DEBUG_EMIT_SYMBOLS => 1;


=head1 Booting phi
phi is the most self-referential project I've ever worked on, so it's not
remotely obvious to me where it bottoms out into a bootstrap script. Let's
figure this out.

First, the main goal of phi is to provide metaclass-aware OOP for a wide variety
of different runtimes with maximal code/data portability. So the language has a
few constraints:

1. Almost everything is written in a semantically consistent bytecode
2. Data layout is done with pre-idiom "logical structs", which are then compiled
3. Structs and classes are portable object instances
4. The interpreter implementation is replaceable and can be GC'd

(GC isn't independently a big deal; objects trace and collect themselves on
backends that don't provide memory management.)

(3) and (4) conspire to make our lives interesting. Jointly, they imply that
every aspect of our bytecode implementations and base objects/structs be
described in terms of objects. Combined with the other constraints, then, we
have three fixed point elements:

1. Classes are and implement objects
2. Bytecode functions are and implement classes
3. Interpreters are instances of and implement classes

phi is designed to implement a minimal solution to these fixed points while
providing a runtime you'd want to use for real problems.


=head2 Lies, damned lies, and dependencies
The world doesn't typically work in X way (for most values of X). So if you're a
sane person who wants some degree of consistency, you have two options: you can
insist that the world does X, or you can do some hacking to make the world
appear to do X. This is the dependency/portability tradeoff. phi, like C,
minimizes dependencies in favor of portability.

Doing this economically requires some parsimony; maintaining a set of C<n>
interconnected lies involves much more than C<O(n)> effort. phi implements the
minimal set of lies required to portably maintain its fixed points. This entails
offloading a lot of things like GC and vtable allocation into libraries.


=head2 Specializing phi to a backend, mechanically speaking
Let's assume machine code or something similarly unstructured for the sake of
argument.

Since the backend is unmanaged, phi needs to implement its own OOP and GC. GC is
entirely library-based; the only backend cooperation we need is direct memory
access and the ability to replace the interpreter.

OOP isn't quite so simple because objects involve behavior, which in turn
requires some set of primitives to perform actions. We can, however, reduce OOP
to a single abstraction: "here's an object with a vtable; now invoke method
number N on it." This is a convenient strategy because it allows us to define a
vtable whose vtable is itself; this covers the first fixed point.

Bytecode is naturally concatenative, which lends itself to a stack-focused
design -- but we have to be a little careful because we run into a few
constraints. First, phi doesn't steal bits from integers; if your system gives
you 64-bit ints, then phi does too. Second, phi's GC is accurate, not
conservative (as it has to be if objects are driving it). Third, phi doesn't
implement stack-wrapping machinery to tag the type of each entry; that is, the
stack is properly untyped.

We can satisfy all three constraints by allocating objects on the stack and
maintaining an active-frame pointer. The only thing we need to do is make sure
we've committed any object pointers into the active frame (or any other
GC-traceable location) before allocating memory; I refer to this as "GC
atomicity." This is something bytecode authors need to be aware of; the bytecode
semantics by themselves don't guarantee that you'll get this right.

Given that bytecode and machine code are both concatenative in nature, we can
define a thin interop convention and implement bytecode natives as machine code
snippets. This and here-pointers (described later on) jointly anchor the second
fixed point by native translation.


=head2 Objects and portability
We totally aren't done yet. Sure, we can have a self-referential vtable thing,
but that works only when the hosting runtime doesn't have opinions about what we
do with memory -- and many environments like Perl, Python, or Java definitely do
have opinions about these things. phi can't afford to be imperialistic about
these differences, which means the object system takes up the slack of backend
awareness. This awareness is the idiom translation layer.

Idiom translation is relevant to phi booting because it's a step between
"logical classes" and compiled objects -- that is, it's a term in the fixed
point equation. Before I get into the details of how this impacts the bootup
process, let's talk about what idiom translation entails.

Let's suppose we have something simple like a key/value pair that maps a string
to an array of integers. Here are some ways we might express this:

  // in Java
  class kvpair {
    String key;
    int[] value;
  }

  // in C
  struct kvpair {
    int   nkey;
    char *key;
    int   nvalues;
    int  *value;
  };

  // in C++
  struct kvpair {
    std::string key;
    std::vector<int> value;
  };

  # in Python
  ("foo", [1, 2, 3])

  # in Perl
  ["foo", [1, 2, 3]]                    # managed representation
  ["foo", pack "V/V", 1, 2, 3]          # flat representation

  (* in OCaml *)
  type kvpair = string * int array

  // in Javascript
  function kvpair() {
    this.key = "";
    this.value = new Int32Array(...);
  }

This is a lot of variation for such a simple class, and that variation brings
some semantic differences as well. For example, Java's strings support 16-bit
characters while C C<char>s are eight bits each. OCaml truncates ints by one bit
for GC type-tagging. C strings will fail for null bytes unless we manually
prefix them with a length.

Some of these decisions are forced but some come down to preference; take Java
for example. Should we use C<String> or C<byte[]>? It depends on the purpose of
the object. Any conversion between C<byte[]> and C<String> incurs a UTF-8
transcoding delay, so we should go with C<String> when we care about
interoperating with existing Java code and C<byte[]> or C<ByteBuffer> when we
want to minimize the cost of migrating values between runtimes.

There's also a question of how we manage and optimize allocation. We're
theoretically at liberty to flatten the string and int array into the object as
value types if those fields aren't shared elsewhere. The tradeoff is much better
memory locality, but we introduce a sizing invariant: once the structure is
allocated we can't do things like extending the key.

The above definitions also gloss over another variation, which is the way types
are encoded. The C, C++, Perl, Python, and OCaml structs are all type-unaware;
if we used any of those objects within a polymorphic context we would need to
add some information to have them support virtual method calls. Each language
uses a different mechanism to implement this.

Basically, the short version of this story is that idiom translation is a pretty
open-ended problem that sometimes demands full automation and other times needs
to be customizable. Bootstrapping is hopeless if we try to model it fully, but
luckily we have a way out: because we're just bootstrapping for a single
backend, we can constant-fold the backend into our idiomatic translation layer
to reduce it to a constant term; then we have a function we can manually apply
to our boot classes to derive vtables.


=head2 Self-descriptive structures
This is far more awful than it sounds, and the reason has to do with machine
code backends. Here's what's up.

We know up front that machine code fragments need to be encased inside objects.
Those objects are then referenced by the interpreter in its bytecode-dispatch
table. So far so good.

When it comes to executing those objects, though, we need to be able to take
those pointers-to-objects and generate machine jump offsets. We could easily do
this by having a fixed offset into the structure, but then we'd lose code
fragment polymorphism. We can't ask the objects themselves for the offsets at
runtime because the code to calculate those offsets is itself implemented in
bytecode. This leaves us two options:

1. Make the rule that machine code must be stored in some fixed object type
2. Ask the objects to precompute their offsets and store those

In the spirit of not being fascist, phi takes option (2) -- and we can optimize
this a little by using here-pointers. Here's how that works.

=head3 Here-pointers
Let's suppose our machine code object looks like this:

  struct machine_code {
    void *vtable;
    int   size;
    char  code[size];
  };

Ideally speaking, we could have the interpreter point straight to
C<machine_code.code> for each instruction; then the dispatch table contains
direct jump addresses and our advancement primitive is simplified to something
simple like C<jmp *(%rdi + 8*%rax)>. That's a beautiful world.

The problem, though, is that while it's completely fine to refer to the middle
of a structure, the garbage collector is going to have to figure out how to
trace through those pointers and ask the individual machine code objects to mark
themselves into a new heap. Then the code pointers will need to be rewritten to
refer to the new allocations. This is what here-pointers are for.

Pointing to the middle of an object is no problem at all if (1) we realize that
this is what's going on, and (2) we have a way to find the object's base
pointer. We get (1) for free with structs, and (2) can be implemented by adding
a two-byte integer immediately before the destination of any mid-pointer:

  struct machine_code {
    void          *vtable;
    int            size;
    unsigned short here_marker = (&(machine_code.code) - &(machine_code));
    char           code[size];
  };

Now we have a simple rule: to convert a here-pointer into a regular pointer, we
just subtract the two-byte unsigned short immediately before it. Everything
remains polymorphic and traceable.

=head3 C<class> protocol
If an object wants to behave like a class, it needs to implement the C<class>
protocol at a minimum. Classes that support idiom translation will implement
more things to make them compilable, but this is what you need to implement to
be interpretable:

  protocol class
  {
    positive_int     size();            # negative = class has variable size
    (cell -> cell)   init_fn();         # initialize for GC atomicity
    ((cell, ?) -> ?) method_fn(symbol); # make a method call against the object
  }

NB: methods are specified as symbols because class/protocol objects are
responsible for allocating and resolving vtable slots (or doing anything else
that implements method calls; phi doesn't require that your classes use
vtables).

NB: C<cell> just refers to the contents of a single stack cell. phi doesn't care
what you put into that cell because the data stack isn't traced for GC.

NB: GC isn't implemented at the struct level; instead, it's a protocol objects
can opt into. This lets you change or replace the GC algorithm at runtime.

Note something interesting here, which is that structs don't specify vtables
directly. This is what lets us implement C<base_pointer> and C<here_pointer> as
structs. For example:

  class here_pointer
  {
    type referent_type;

    implement protocol class
    {
      positive_int size() { 8 }         # always 8 bytes
      fn init_fn() { [] }               # no initialization necessary
      fn method_fn(symbol m)
      {
        # dereference ourselves, then delegate to whatever the base pointer
        # would have done
        [                               # self-ptr
          dup -2 +                      # self self-2
          mget16 neg +                  # base-ptr
        ] ++ base_pointer(referent_type).method_fn(m);
      }
    }
  }

Arrays and aggregate accessors are implemented as methods. So C<xs[3]> becomes a
method call C<xs.[](3)>; C<a_bar.f1> is a method call to C<.f1()> rather than a
direct field access. C<a_bar = ...> is also a method call: C<a_bar.=(...)>. The
expected signature of C<=> is C<< val -> val >>; it's an identity function (with
side effects) for reference types.

NB: field accessors typically return C<base_pointer(...)>; otherwise assignment
would be unable to update anything. That is, C<a_bar.f1.x = 1.0> works by having
C<a_bar.f1.x> resolve to a C<base_pointer(double)>. This means assignment is
type-overloaded: C<double* = double*> and C<double* = double> both work and must
be statically resolved.

=head3 C<struct> class
We can get C<struct>-style behavior by implementing a class that keeps track of
subfields and generates methods to access them. It looks something like this:

  class struct
  {
    list(pair(symbol, class)) fields;

    fn offset_of(symbol field) { ... }

    implement protocol class
    {
      positive_int size() { fields.map(x.second.size).sum }

      fn init_fn()
      {
        # initialize each field
      }

      fn method_fn(symbol m)
      {
        # return a base pointer to whichever field is referred to
      }
    }
  }

Classes can then ask an instance of C<struct> for field offsets, or you could
use the struct as a class directly.

=head3 C<polymorphic> class
All of the classes I've mentioned so far are monomorphic, but in practice most
OOP involves polymorphism. This is implemented with the C<polymorphic> class:

  class polymorphic
  {
    protocol p;

    implement protocol class
    {
      maybe_int size()
      {
        p.alternatives.map(x.size).max + sizeof(here_ptr(vtable));
      }

      fn init_fn() { ... }              # ask protocol for a default init

      fn method_fn(method m)
      {
        # generate a virtual method call against the vtable
      }
    }
  }

C<polymorphic> promotes protocols to classes. It's common to see it used with
pointers, for instance C<base_pointer(polymorphic(a_protocol))>. This is the
implied type of every protocol field in the class definitions above.

=head3 Variable-sized classes
It's useful to be able to write classes whose size is instance-dependent, like
this C string struct:

  struct string {
    size_t len;
    char   chars[0];                    // really chars[len]
  };

Anyone allocating this struct would then add the length to the size of the
struct: C<malloc(sizeof(string) + len)>.

You lose some flexibility if you do this: you can't have an array of strings,
for example, and you have to make sure everyone who uses one knows to do special
C<sizeof> stuff rather than asking C. You also can't inline C<string> into
another struct; you would need to use a pointer, or make sure your C<string> was
the last element if you (inadvisably) inlined it, propagating the issue.

There are some upsides though. First, compared to using the usual C<char*>, it
saves a memory allocation and a pointer dereference -- cache locality is greatly
improved since you'd need to load the line for C<len> either way. Second,
because there are no pointers, these structures are self-serializing: you could
C<mmap> one to any address and it would work. (And nothing prevents you from
having a bunch of them in a row; you'd just need to index their positions if you
wanted efficient random access.) Third, the inline-char structure is more
space-efficient than it would be if it used C<char*> -- we've saved the space
required to store the pointer, which could be up to 33% if we have a bunch of
small strings.

Things like memory allocations and cache locality matter in a GC'd world too.
Every pointer is something you have to trace when you mark objects, so you want
to minimize indirection unless you specifically need those degrees of freedom
(e.g. for a mutable and self-reallocating C<string>).

...all of that to say, phi supports variable-sized classes because they're
useful. Just like in C or Java, you can't change the size of an object after
you've created it -- C<realloc> isn't a thing because we don't know who might be
referring to our value. So another way to look at it is that phi supports
size-parameterized classes. (TODO: the class protocol needs to be able to
describe the size of an object in better terms, or maybe objects just have a
C<.size> method for this.)

Q: is it appropriate to use C<polymorphic> as a wrapper type and then be on the
hook for providing a C<size> method for allocation purposes? In practice each
object will be just one type; you can't generally transform something into a
differently-typed instance unless you manually reserve space to do that.
C<polymorphic> shouldn't use the max-size heuristic anyway because it would be
incredibly wasteful. Instead, we should have classes follow some kind of
protocol that tells us what they are; then C<polymorphic> simply asserts that
each alternative follows the same such protocol.


=head2 Boot objects
OK, let's forget the pretense of having metaclasses for a minute and just talk
about what we need to encode stuff. We have a few types of objects for sure:

1. Bytecode functions (binary strings of bytecode)
2. Native functions (binary strings of machine code)
3. vtable objects
4. Interpreters (and heaps?)
5. Generic call frames
6. Base pointers
7. Here-pointers

That gets us to a self-encoding state. All of the class/protocol stuff can be
used to _generate_ vtables, but we could also use some other mechanism if we
cared to. Practically speaking, all we need are functions (bytecode things) that
allocate values.

Interestingly, we don't need primitive value types for bootup. Primitive values
reduce to stack-addressed bytecode operations (e.g. C<int.+> is effectively the
same thing as the C<int+> instruction) and don't use vtables for any type of
polymorphism.

Technically we could emit single-protocol vtables and be done for bootstrapping
purposes. That would run correctly, but that information alone isn't enough for
the resulting image to recompile itself; it would be forced to interpret those
vtables verbatim, which would make it impossible to modify any method
definitions or even resolve symbols to methods (due to protocol erasure). So we
need to emit some structural representation of the protocols we care about along
with the vtables they produce.

...and that means we'll need a couple more things for our image:

8. Class objects
9. Protocol objects

=head3 Dual implementation and the self-reference critical path
If the boot image's behavior depends on an object, then we'll need two
implementations of it: one in perl and one in phi. Otherwise (if the object is
just data for bootstrapping purposes), we can get away with just implementing it
in phi. Any Perl code we write is effectively throwaway: Perl is a simple enough
language that we don't have tons of magic we could inherit from the boot process
if we dropped it into the image.

We can also lie to phi to save effort. For example, vtables link to the classes
that produced them but that linkage is strictly informational: there's no
requirement that those classes would reproduce _those_ vtables. This means we
can generate boot-time vtables that all use a single protocol, but tell phi that
we have some well-thought-out class/protocol system. phi can then recompile the
vtables accordingly if it needs to. (The reason all of this must work is that
classes and protocols are mutable objects, so at any given moment there's no
implication that they would be in a state consistent with the vtables they had
at generated at a different moment in time.)

Anyway, all of this just lets us save ourselves a little bit of effort when
we're putting phi together.

=head3 Let's kick this off: binary native/bytecode strings
We can share a class for these two things, which is useful because they have
similar constraints. Here's the structure:

  type ref = { uint8_t ref_type; uint16_t offset };

  hereptr<vtable> vtable;               # 8 bytes
  baseptr<object> source;               # 8 bytes
  uint16_t nrefs;                       # 2 bytes
  uint16_t codesize;                    # 2 bytes
  ref[nrefs] refs;                      # 3*nrefs bytes
  uint16_t here_marker;                 # 2 bytes
  char code[codesize];                  # codesize bytes

So far so good, but why does the object itself encode a vtable -- isn't that why
we have C<polymorphic>? Technically, yes it is. The object above isn't the
structure of C<code_string>; it's actually the structure of
C<polymorphic(a_protocol)> (where C<code_string> implements C<a_protocol>). We
don't allocate it this way because C<polymorphic> won't know how much space to
reserve for the code string -- in part because code strings themselves don't
have a fixed size. (TODO: this really feels like it's going to end up being a
problem ... is this going to work?)
=cut


1;
