#!/usr/bin/env perl

=head1 License
    phi programming language
    Copyright (C) 2018  Spencer Tipping

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU Affero General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU Affero General Public License for more details.

    You should have received a copy of the GNU Affero General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.


=head1 phi boot image generator
This script emits a Linux/AMD64 machine code image. We aren't linked to any
libraries (including libc), so everything bottoms out in terms of system calls
and we aren't at all portable to other POSIX systems. This is an OK place to
start the world; later on we can specify how to build a C+JIT system that
interfaces to system functions using the standard C calling convention. The
image can then port itself to this backend.

Not all backends are low-level; we just start there because it's conveniently
minimalistic. phi can also recompile itself to languages like Javascript,
Python, Ruby, Perl, OCaml, Java, etc, each of which provides some form of GC
and/or OOP. phi is set up to delegate to hosting facilities when they're
available. (Optimizing effectively for each backend is another story that I'll
address within the phi codegen libraries.)
=cut

package phi;

use v5.14;          # required for pack() endian modifiers, // operator
use strict;
use warnings;
use List::Util qw/sum/;
no warnings 'void';

use Carp;

BEGIN
{
  $Carp::Verbose = 1;
  $SIG{__DIE__} = sub { Carp::confess @_ };
}


=head2 General build/debug settings
We want to be able to inspect various aspects of phi's behavior quickly, so I've
built in a bunch of conditional build settings that compile debug tracers into
the image if we need them.
=cut

use constant DEBUG_TRACE_INSNS  => 0;
use constant DEBUG_EMIT_SYMBOLS => 1;


=head1 Booting phi
phi is the most self-referential project I've ever worked on, so it's not
remotely obvious to me where it bottoms out into a bootstrap script. Let's
figure this out.

First, the main goal of phi is to provide metaclass-aware OOP for a wide variety
of different runtimes with maximal code/data portability. So the language has a
few constraints:

1. Almost everything is written in a semantically consistent bytecode
2. Data layout is done with pre-idiom "logical structs", which are then compiled
3. Structs and classes are portable object instances
4. The interpreter implementation is replaceable and can be GC'd

(GC isn't independently a big deal; objects trace and collect themselves on
backends that don't provide memory management.)

(3) and (4) conspire to make our lives interesting. Jointly, they imply that
every aspect of our bytecode implementations and base objects/structs be
described in terms of objects. Combined with the other constraints, then, we
have three fixed point elements:

1. Classes are and implement objects
2. Bytecode functions are and implement classes
3. Interpreters are instances of and implement classes

phi is designed to implement a minimal solution to these fixed points while
providing a runtime you'd want to use for real problems.


=head2 Lies, damned lies, and dependencies
The world doesn't typically work in X way (for most values of X). So if you're a
sane person who wants some degree of consistency, you have two options: you can
insist that the world does X, or you can do some hacking to make the world
appear to do X. This is the dependency/portability tradeoff. phi, like C,
minimizes dependencies in favor of portability.

Doing this economically requires some parsimony; maintaining a set of C<n>
interconnected lies involves much more than C<O(n)> effort. phi implements the
minimal set of lies required to portably maintain its fixed points. This entails
offloading a lot of things like GC and vtable allocation into libraries.


=head2 Specializing phi to a backend, mechanically speaking
Let's assume machine code or something similarly unstructured for the sake of
argument.

Since the backend is unmanaged, phi needs to implement its own OOP and GC. GC is
entirely library-based; the only backend cooperation we need is direct memory
access and the ability to replace the interpreter.

OOP isn't quite so simple because objects involve behavior, which in turn
requires some set of primitives to perform actions. We can, however, reduce OOP
to a single abstraction: "here's an object with a vtable; now invoke method
number N on it." This is a convenient strategy because it allows us to define a
vtable whose vtable is itself; this covers the first fixed point.

Bytecode is naturally concatenative, which lends itself to a stack-focused
design -- but we have to be a little careful because we run into a few
constraints. First, phi doesn't steal bits from integers; if your system gives
you 64-bit ints, then phi does too. Second, phi's GC is accurate, not
conservative (as it has to be if objects are driving it). Third, phi doesn't
implement stack-wrapping machinery to tag the type of each entry; that is, the
stack is properly untyped.

We can satisfy all three constraints by allocating objects on the stack and
maintaining an active-frame pointer. The only thing we need to do is make sure
we've committed any object pointers into the active frame (or any other
GC-traceable location) before allocating memory; I refer to this as "GC
atomicity." This is something bytecode authors need to be aware of; the bytecode
semantics by themselves don't guarantee that you'll get this right.

Given that bytecode and machine code are both concatenative in nature, we can
define a thin interop convention and implement bytecode natives as machine code
snippets. This and here-pointers (described later on) jointly anchor the second
fixed point by native translation.


=head2 Objects and portability
We totally aren't done yet. Sure, we can have a self-referential vtable thing,
but that works only when the hosting runtime doesn't have opinions about what we
do with memory -- and many environments like Perl, Python, or Java definitely do
have opinions about these things. phi can't afford to be imperialistic about
these differences, which means the object system takes up the slack of backend
awareness. This awareness is the idiom translation layer.

Idiom translation is relevant to phi booting because it's a step between
"logical classes" and compiled objects -- that is, it's a term in the fixed
point equation. Before I get into the details of how this impacts the bootup
process, let's talk about what idiom translation entails.

Let's suppose we have something simple like a key/value pair that maps a string
to an array of integers. Here are some ways we might express this:

  // in Java
  class kvpair {
    String key;
    int[] value;
  }

  // in C
  struct kvpair {
    int   nkey;
    char *key;
    int   nvalues;
    int  *value;
  };

  // in C++
  struct kvpair {
    std::string key;
    std::vector<int> value;
  };

  # in Python
  ("foo", [1, 2, 3])

  # in Perl
  ["foo", [1, 2, 3]]                    # managed representation
  ["foo", pack "V/V", 1, 2, 3]          # flat representation

  (* in OCaml *)
  type kvpair = string * int array

  // in Javascript
  function kvpair() {
    this.key = "";
    this.value = new Int32Array(...);
  }

This is a lot of variation for such a simple class, and that variation brings
some semantic differences as well. For example, Java's strings support 16-bit
characters while C C<char>s are eight bits each. OCaml truncates ints by one bit
for GC type-tagging. C strings will fail for null bytes unless we manually
prefix them with a length.

Some of these decisions are forced but some come down to preference; take Java
for example. Should we use C<String> or C<byte[]>? It depends on the purpose of
the object. Any conversion between C<byte[]> and C<String> incurs a UTF-8
transcoding delay, so we should go with C<String> when we care about
interoperating with existing Java code and C<byte[]> or C<ByteBuffer> when we
want to minimize the cost of migrating values between runtimes.

There's also a question of how we manage and optimize allocation. We're
theoretically at liberty to flatten the string and int array into the object as
value types if those fields aren't shared elsewhere. The tradeoff is much better
memory locality, but we introduce a sizing invariant: once the structure is
allocated we can't do things like extending the key.

The above definitions also gloss over another variation, which is the way types
are encoded. The C, C++, Perl, Python, and OCaml structs are all type-unaware;
if we used any of those objects within a polymorphic context we would need to
add some information to have them support virtual method calls. Each language
uses a different mechanism to implement this.

Basically, the short version of this story is that idiom translation is a pretty
open-ended problem that sometimes demands full automation and other times needs
to be customizable. Bootstrapping is hopeless if we try to model it fully, but
luckily we have a way out: because we're just bootstrapping for a single
backend, we can constant-fold the backend into our idiomatic translation layer
to reduce it to a constant term; then we have a function we can manually apply
to our boot classes to derive vtables.


=head2 Self-descriptive structures
This is far more awful than it sounds, and the reason has to do with machine
code backends. Here's what's up.

We know up front that machine code fragments need to be encased inside objects.
Those objects are then referenced by the interpreter in its bytecode-dispatch
table. So far so good.

When it comes to executing those objects, though, we need to be able to take
those pointers-to-objects and generate machine jump offsets. We could easily do
this by having a fixed offset into the structure, but then we'd lose code
fragment polymorphism. We can't ask the objects themselves for the offsets at
runtime because the code to calculate those offsets is itself implemented in
bytecode. This leaves us two options:

1. Make the rule that machine code must be stored in some fixed object type
2. Ask the objects to precompute their offsets and store those

In the spirit of not being fascist, phi takes option (2) -- and we can optimize
this a little by using here-pointers. Here's how that works.

=head3 Here-pointers
Let's suppose our machine code object looks like this:

  struct machine_code {
    void *vtable;
    int   size;
    char  code[size];
  };

Ideally speaking, we could have the interpreter point straight to
C<machine_code.code> for each instruction; then the dispatch table contains
direct jump addresses and our advancement primitive is simplified to something
simple like C<jmp *(%rdi + 8*%rax)>. That's a beautiful world.

The problem, though, is that while it's completely fine to refer to the middle
of a structure, the garbage collector is going to have to figure out how to
trace through those pointers and ask the individual machine code objects to mark
themselves into a new heap. Then the code pointers will need to be rewritten to
refer to the new allocations. This is what here-pointers are for.

Pointing to the middle of an object is no problem at all if (1) we realize that
this is what's going on, and (2) we have a way to find the object's base
pointer. We get (1) for free with structs, and (2) can be implemented by adding
a two-byte integer immediately before the destination of any mid-pointer:

  struct machine_code {
    void          *vtable;
    int            size;
    unsigned short here_marker = (&(machine_code.code) - &(machine_code));
    char           code[size];
  };

Now we have a simple rule: to convert a here-pointer into a regular pointer, we
just subtract the two-byte unsigned short immediately before it. Everything
remains polymorphic and traceable.

NB: we can create here-pointers in any unmanaged language, including in C even
with uncertain/inconsistent struct padding. We know that the padding is always
at least large enough for a C<here_marker>, so we can take the here-pointer,
back up two bytes, and write in the offset. We don't know how that position
relates to the address of C<here_marker>, but we don't have to -- here pointers
are positioned relative to the thing after them. (This means we'll have to be
careful with C because we can't expect to use the C<here_marker> field even
though it's present in the struct.)

=head3 C<gc> protocol
Objects need to be able to copy themselves into a new heap for GC purposes. The
protocol looks like this:

  protocol heap {
    base_pointer allocate(size);
  }

  protocol gc {
    cell mark_into(heap);
    void mark_in_place(heap);
  }

NB: C<mark_in_place> will fail horribly if you base-point to an inline object.
We should probably have disjoint protocol behaviors, one for inline-allocated
objects and one for reference objects. Some objects don't need to implement
C<gc> at all, particularly if they're unilaterally managed by a container.

A typical C<mark_into(heap)> implementation would look like this:

  copy self into new heap
  set *self+8 to the new address
  modify self.vtable to the "already marked" object type
  for each pointer field:
    new self.field = new self.field.mark_into(heap)
  return new self

This will copy the object exactly, which isn't a bad start. But we can often do
better. Since we have to copy the object either way, we can apply structural
optimizations in the process. This is a side-benefit of having objects own their
own GC. For example, a linked list could decide to inline a bunch of elements
into condensed blocks, thus incrementally converting itself into a chunked
sequence. Data structures are responsible for minimizing their amortized GC
overhead.

This design (and a lot about phi) creates the limitation that we can't support
any incremental or concurrent GC; garbage collection -- or more accurately heap
rewriting -- is an atomic operation that occurs separately from normal program
execution.

I'm ok with this limitation. We can't have objects rewrite themselves if the GC
is in any way concurrent; we don't know who will try to access them while
they're being rewritten. Concurrent/incremental GC is also strictly less
efficient than serial GC; the trade is between efficiency and low latency.
(Also, the train has long since sailed for concurrent GC given the way atomicity
works.)

Finalizers are easy to implement. The GC protocol includes a C<finalize> method,
which C<gc_marked> implements as a no-op. Objects interested in being finalized
add themselves to a finalization list maintained by the heap. Then, after all
objects are marked, the GC loops through the finalization list and invokes
everyone's C<finalize>.

Code run within a finalizer sees a slightly different version of the world.
C<gc_marked> behaves like a pointer to an object's new location -- so no worries
there -- but you can't do things like resurrect objects or persist modifications
to collected memory. You also can't resurrect the object being finalized.
Finalizers are strictly for things like freeing externally allocated resources.

...so: phi's GC is simple by design. When you need better throughput/latency/etc
you have options to manage memory to get those results (for instance, writing a
custom heap class, pointers, and GC algorithm).


=head3 Object size and allocation
The heap is compact; that is, each object is allocated immediately after the
previous one. phi isn't strictly required to do it this way, but it's also not
required to let you expand an existing allocation. This means objects need to
know how large they are at allocation-time. Dynamically-sized objects result in
garbage as they allocate new, larger buffers when required (e.g. variable-sized
array objects).

This creates a natural delegation: part of the C<class> protocol specifies an
C<allocate> method that accepts ctor arguments and returns a base pointer to the
new instance. If the class is a value type, C<allocate> returns the value
itself. The class owns its allocation contract and specifies it by returning
C<instance_type>, the thing that C<allocate> will return. Almost every class
provides an C<instance_type> that fits into a single stack slot, e.g. a pointer
or an C<int> or something.

Classes are allowed to provide a fixed allocation size, which is useful for
things like arrays. This is a separate protocol.


=head3 C<class> protocol
If an object wants to behave like a class, it needs to implement the C<class>
protocol at a minimum. Classes that support idiom translation will implement
more things to make them compilable, but this is what you need to implement to
be interpretable:

  type method = symbol;                 # not literally true, but close enough
  protocol class
  {
    type instance = cell | ...;
    type                 instance_type();
    instance             new(...);      # aka allocate()
    ((instance, ?) -> ?) method_fn(method);
  }

NB: methods are specified semantically because class/protocol objects are
responsible for allocating and resolving vtable slots (or doing anything else
that implements method calls; phi doesn't require that your classes use
vtables).

Note something interesting here, which is that structs don't specify vtables
directly. This is what lets us implement C<base_pointer> and C<here_pointer> as
value-type classes. For example:

  class here_pointer
  {
    type referent_type;

    implement protocol fixed_size
    {
      size size() { native_machine_word }
    }

    implement protocol class
    {
      type instance_type()                    { here_pointer }
      here_pointer<referent_type> allocate(x) { x }
      fn method_fn(symbol m)
      {
        # dereference ourselves, then delegate to whatever the base pointer
        # would have done
        [                               # self-ptr
          dup -2 +                      # self self-2
          mget16 neg +                  # base-ptr
        ] ++ base_pointer(referent_type).method_fn(m);
      }
    }
  }

Arrays and aggregate accessors are implemented as methods. So C<xs[3]> becomes a
method call C<xs.[](3)>; C<a_bar.f1> is a method call to C<.f1()> rather than a
direct field access. C<a_bar = ...> is also a method call: C<a_bar.=(...)>. The
expected signature of C<=> is C<< val -> val >>; it's an identity function (with
side effects) for reference types.

NB: field accessors typically return C<base_pointer(...)>; otherwise assignment
would be unable to update anything. That is, C<a_bar.f1.x = 1.0> works by having
C<a_bar.f1.x> resolve to a C<base_pointer(double)>. This means assignment is
type-overloaded: C<double* = double*> and C<double* = double> both work and must
be statically resolved.


=head3 Polymorphism
Polymorphic values are usually pointed to by C<base_pointer> or C<here_pointer>,
but they don't have to be. Polymorphic values also don't have to be reference
types. So two things aren't completely obvious:

1. Who's responsible for resolving RTTI and producing a vtable?
2. If we write C<< base_pointer<numeric> >>, who adds RTTI to C<int> and how?

(1) arguably falls to the class providing the method-calling interface, which in
this case is the pointer class. But pointers don't know how a given type will
store its RTTI (if any), nor should they. Maybe we have a compact multi-purpose
primitive type with three tag bits and 61 data bits or something. We should be
able to base-point to that without the pointer having to know what insane
strategy the referent is using.

(1) informs (2): the RTTI encoding strategy could be pretty much anything, so
there isn't a default way to add RTTI to things like primitives. In short, you
can't actually write C<< base_pointer<numeric> >>: you have to point to a class
rather than to a protocol. This means we need a way to convert one to another.
So we'd write C<< base_pointer<vtable_polymorphic<numeric> > >>.

C<vtable_polymorphic> is a general-purpose strategy for RTTI, but it may be
overkill; if C<numeric> has exactly two alternatives then we'd be using 64 bits
to encode one bit of information. That's obviously a tragedy; let's discuss how
to deal with it. We have a few options:

1. Use a tag bit
2. Use a one-byte prefix instead of the full vtable pointer (8 bits for one bit)
3. If we have an array, use a separate bit vector to store type bits
4. We rely on something domain-specific like NaN

Of these, (3) is interesting and deserves some discussion because it has broad
implications for collection types and small-polymorphism optimization.

=head4 Array element polymorphism and semi-boxing
There's no excuse to have arrays fully box small-polymorphic values of
fixed+equal size. For example, C<< array<int64|double> >> should absolutely not
result in an array of pointers to vtable-prefixed ints/doubles; that would be
egregious for two reasons:

1. 66% of the space usage of this structure is pointers
2. The cache-miss GC complexity of this structure is C<O(keep)>

The space-optimal solution is to have the array maintain a bit vector of type
bits that differentiate between C<int64> and C<double> for each element. Now we
have a new challenge, though: suppose we write something like C<xs[i] + 1>. What
does C<xs[i]> return in order to correctly resolve the C<+> method?

Here's why this isn't straightforward. The return value from C<xs[i]> is some
kind of indexed pointer. It can't be a C<base_pointer> to anything because the
referent won't have any way to encode its type; by that point we would have lost
the bit vector entry we'd use to resolve it. So we need C<xs[i]> to refer both
to the element and to its type.

A simple option is to have C<xs[i]> return a two-slot value consisting of a
vtable and the element (or a pointer to the element). Then we'd have a new value
type, C<externally_tagged_pointer>, whose size is 16 bytes. This may be a bit
clunky but is still far superior to having fully boxed values. A solution
exists; we're in good shape.


=head2 Boot objects
OK, let's forget the pretense of having metaclasses for a minute and just talk
about what we need to encode stuff. We have a few types of objects for sure:

1. Bytecode functions (binary strings of bytecode)
2. Native functions (binary strings of machine code)
3. vtable objects
4. Interpreters (and heaps?)
5. Generic call frames
6. Base pointers
7. Here-pointers

That gets us to a self-encoding state. All of the class/protocol stuff can be
used to _generate_ vtables, but we could also use some other mechanism if we
cared to. Practically speaking, all we need are functions (bytecode things) that
allocate values.

Interestingly, we don't need primitive value types for bootup. Primitive values
reduce to stack-addressed bytecode operations (e.g. C<int.+> is effectively the
same thing as the C<int+> instruction) and don't use vtables for any type of
polymorphism. In other words, primitive types play no role in RTTI for the base
image, so they end up being fully erased.

Technically we could emit single-protocol vtables and be done for bootstrapping
purposes. That would run correctly, but that information alone isn't enough for
the resulting image to recompile itself; it would be forced to interpret those
vtables verbatim, which would make it impossible to modify any method
definitions or even resolve symbols to methods (due to protocol erasure). So we
need to emit some structural representation of the protocols we care about along
with the vtables they produce.

...and that means we'll need a couple more things for our image:

8. Class objects
9. Protocol objects


=head3 Dual implementation and the self-reference critical path
If the boot image's behavior depends on an object, then we'll need two
implementations of it: one in perl and one in phi. Otherwise (if the object is
just data for bootstrapping purposes), we can get away with just implementing it
in phi. Any Perl code we write is effectively throwaway: Perl is a simple enough
language that we don't have tons of magic we could inherit from the boot process
if we dropped it into the image.

We can also lie to phi to save effort. For example, vtables link to the classes
that produced them but that linkage is strictly informational: there's no
requirement that those classes would reproduce _those_ vtables. This means we
can generate boot-time vtables that all use a single protocol, but tell phi that
we have some well-thought-out class/protocol system. phi can then recompile the
vtables accordingly if it needs to. (The reason all of this must work is that
classes and protocols are mutable objects, so at any given moment there's no
implication that they would be in a state consistent with the vtables they had
generated at a different moment in time.)

Anyway, all of this just lets us save ourselves a little bit of effort when
we're putting phi together.


=head3 The big picture
Before I get into the details, let's talk briefly about how we get this language
off the ground. What we have now is a VM spec: we know how the
interpreter/GC/etc work, but nothing yet about the language frontend (nor how we
get to the point where we're building one).

TODO: explain parsing protocols/functions

NB: parse states can and should be value types; no sense in forcing a heap
allocation where we don't need one.


=head3 Let's kick this off: binary native/bytecode strings
We can share a class for these two things, which is useful because they have
similar constraints. Here's the structure:

  type ref = { uint8_t ref_type; uint16_t offset };

  baseptr<object> source;               # 8 bytes
  uint16_t nrefs;                       # 2 bytes
  uint16_t codesize;                    # 2 bytes
  ref[nrefs] refs;                      # 3*nrefs bytes
  uint16_t here_marker;                 # 2 bytes
  char code[codesize];                  # codesize bytes

NB: if we ask the above structure for a C<here_pointer> to its code,
C<here_marker> will offset from C<source> -- _after_ the vtable prefix --
because code buffers are unaware of vtable encoding strategy; i.e. they're
untyped until we make them polymorphic and specify how.


=head3 Writing code in perl
We can hack this together with a mixture of C<pack> and C<bin>, the latter being
a mixed hex/octal format that's ideal for writing machine code. Here's C<bin>:
=cut

use constant bin_macros => {};

sub bin($)
{
  my @parts;
  local $_ = shift;
  while (length)
  {
    next                                        if s/^\s+|^#.*\n?//;
    push(@parts, pack "H*", $1), next           if s/^x?((?:[0-9a-fA-F]{2})+)//;
    push(@parts, pack "C", oct $1), next        if s/^o([0-3][0-7]{2})//;
    push(@parts, bin_macros->{$1} // die), next if s/^(\w)//;
    die "phi::bin: failed to parse starting at $_";
  }
  join"", @parts;
}


=head3 Machine code primitives
These implement bytecodes for the interpreter, which means we need a register
convention at this point. Let's go ahead and define that.

  %rsp = data and return stack
  %rbp = frame pointer
  %rdi = current interpreter hereptr (to instruction vector)
  %rsi = next bytecode instruction address

Like Jonesforth, each machine code primitive ends with an advancement snippet to
load the next instruction. If we're executing the first bytecode instruction
within a bytecode string, here's what our registers are pointing to:

    %rdi -----+
              |
              V
  here_marker insn0* insn1* insn2* ... insn255*
              |8bytes|8bytes|...


  %rsi -----+
            |
            V
  bytecode0 bytecode1 ... bytecodeN
  |1 byte   |

  %rax = bytecode0

Therefore, if we assume the high 56 bits of C<%rax> are zero, our advancement
looks like this:

  lodsb
  jmp *(%rdi + 8*%rax)

Instructions are individually responsible for clearing the high bits of C<%rax>.
=cut

use constant mc_next => bin"
  ac                                    # lodsb
  ffo044o307                            # jmp *(%rdi + 8*%rax)";

BEGIN { bin_macros->{N} = mc_next }


=head3 Bytecode allocation
Bytecodes fall into a few groups:

  0x00 - 0x0f: reserved -- these will crash the interpreter
  0x10 - 0x1f: push a constant
  0x20 - 0x2f: interpreter-related things: call a function/native, etc
  0x30 - 0x3f: stack functions: swap/dup/drop/etc
  0x40 - 0x4f: memory functions, if the backend supports them
  0x50 - 0x5f: integer math
  0x60 - 0x6f: float math, if the backend supports them
  everything else: reserved

=cut

use constant bytecodes => [];
sub bcset { die if @_ & 1; bytecodes->[$_[0]] = $_[1], shift, shift while @_ }


=head4 Constant-pushing functions
These each net one stack value, either embedded into the instruction or read as
a literal from the bytecode. Multibyte quantities are read in big-endian form.

  0x10 = push 8-bit literal int (immediately after bytecode)
  0x11 = push 16-bit literal int
  0x12 = push 32-bit literal int
  0x13 = push 64-bit literal int
  0x14 - 0x1f = push literal small int 0-11

All literals are unsigned, so no sign extension happens. You can encode negative
literals either using the full 64-bit form, or by using C<ineg> to negate a
positive integer.
=cut

bcset
  0x10 => bin"  ac        50 N",        # lodsb;                push %rax
  0x11 => bin"66ad 86o340 50 31o300 N", # lodsw; xchg %al, %ah; push %rax
  0x12 => bin"  ad 0fc8   50 31o300 N", # lodsd; bswap %eax;    push %rax
  0x13 => bin"48ad 480fc8 50 31o300 N", # lodsq; bswap %rax;    push %rax

  map(($_ => bin"80o300ec 50 N"),       # add %al, -0x14; push %rax
      0x14 .. 0x1f);


=head4 Interpreter functions
This is the most complicated section because we have some open-ended stuff going
on.

  0x20 = call native here-ptr
  0x21 = call bytecode here-ptr
  0x22 = 8-bit vtable bytecode mcall (vtable address on stack)
  0x23 = 16-bit vtable bytecode mcall (vtable address on stack)

  0x24 = if
  0x25 = alloca (decrements %rbp by immediate, then empties stack against %rbp)

  0x28 = get-frameptr
  0x29 = set-frameptr
  0x2a = get-interpptr
  0x2b = set-interpptr
  0x2c = get-stackptr
  0x2d = set-stackptr

C<call_native> jumps straight into some machine code whose address you specify
(presumably with a C<here_pointer>). That machine code needs to preserve phi's
registers and manually advance the interpreter to return. The stack, C<%rsi>,
etc all come in unmodified.

C<call_bytecode> swaps the target here-pointer address with C<%rsi> on the
stack. It's up to you to make sure you have a way to preserve the callee for GC
purposes if you need GC atomicity -- in practice this tends to be managed by the
function prologue that allocates the stack frame.
=cut

bcset
  0x20 => bin"59 48ffo341",             # pop %rcx; jmp %rcx (no next required)
  0x21 => bin"4887o064o044 N",          # xchg *%rsp, %rsi

  0x22 => bin"59                        # pop %rcx
              ac                        # lodsb
              56                        # push %rsi
              488bo064o301 N            # movq *(%rcx + 8*%rax), %rsi",

  0x23 => bin"59                        # pop %rcx
              66ad                      # lodsw
              56                        # push %rsi
              86o340                    # xchg %al, %ah
              488bo064o301              # movq *(%rcx + 8*%rax), %rsi
              31o300 N                  # xor %eax, %eax",

  0x24 => bin"595a5b                    # else->%rcx, then->%rdx, cond->%rbx
              4885o333                  # test %rbx, %rbx
              480f45o312                # cmovnz %rdx, %rcx
              51 N                      # push %rcx",

  0x25 => bin"ac                        # lodsb
              482bo350                  # subq %rax, %rbp
              488bo345 N                # movq %rbp, %rsp",

  0x28 => bin"55 N",                    # push %rbp
  0x29 => bin"5d N",                    # pop %rbp
  0x2a => bin"57 N",                    # push %rdi
  0x2b => bin"5f N",                    # pop %rdi
  0x2c => bin"54 N",                    # push %rsp
  0x2d => bin"5c N";                    # pop %rsp


=head4 Stack functions
Just enough stuff to manipulate operands for primitives. Most data accesses
address the current frame.

  0x30 = dup
  0x31 = drop
  0x32 = swap
  0x33 = frame-get-nth (literal 8-bit n)
  0x34 = frame-set-nth (literal 8-bit n)

=cut

bcset
  0x30 => bin"595151 N",                # pop %rcx; push %rcx, %rcx
  0x31 => bin"59 N",                    # pop %rcx
  0x32 => bin"595a5152 N",              # pop %rcx, %rdx; push %rcx, %rdx
  0x33 => bin"ac ffo164o30500 N",       # lodsb; pushq *(%rbp + 8*%rax)
  0x34 => bin"ac 8fo104o30500 N";       # lodsb; popq *(%rbp + 8*%rax)


=head4 Memory functions
Memory get/set in various sizes. No endian-conversion happens here, so you'll
have to byteswap if you're writing constants into bytecode on x86.

  0x40 = m8get
  0x41 = m8set
  0x42 = m16get
  0x43 = m16set
  0x44 = m32get
  0x45 = m32set
  0x46 = m64get
  0x47 = m64set
  0x48 = memcpy

=cut

bcset
  0x40 => bin"59 8ao001 50 N",          # pop %rcx; movb *%rcx, %al; push %rax
  0x42 => bin"59 0fb7o011 51 N",        # pop %rcx; movzx *%rcx, %ecx; push %rcx
  0x44 => bin"59 8bo011 51 N",          # pop %rcx; movd *%rcx, %ecx; push %rcx
  0x46 => bin"59 ffo061 N",             # pop %rcx; pushq *%rcx

  0x41 => bin"5a59 88o021 N",           # pop %rdcx; movb %dl,  *%rcx
  0x43 => bin"5a59 6689o021 N",         # pop %rdcx; movw %dx,  *%rcx
  0x45 => bin"5a59 89o021 N",           # pop %rdcx; movd %edx, *%rcx
  0x47 => bin"5a59 4889o021 N",         # pop %rdcx; movq %rdx, *%rcx

  0x48 => bin"59                        # pop size -> %rcx
              488bo337                  # movq %rdi, %rbx
              5f                        # pop dest -> %rdi
              488bo326                  # movq %rsi, %rdx
              5e                        # pop source -> %rsi
              f348a4                    # rep(%rcx) movsb
              488bo362                  # movq %rdx, %rsi
              488bo373 N                # movq %rbx, %rdi";


=head4 Integer instructions
The usual suspects, on full-width stack cells. Operations are signed by default.

  0x50 = iplus
  0x51 = itimes
  0x52 = ishl
  0x53 = isar
  0x54 = ishr
  0x55 = iand
  0x56 = ior
  0x57 = ixor
  0x58 = i<
  0x59 = i==
  0x5a = iinv
  0x5b = ineg
  0x5c = bswap16
  0x5d = bswap32
  0x5e = bswap64

=cut

bcset
  0x50 => bin"59 4801o014o044 N",       # pop %rcx; add %rcx, *%rsp
  0x51 => bin"595a 480fafo321 52 N",    # pop %rcdx; imul %rcx, %rdx; push %rdx
  0x52 => bin"59 48d3o044o044 N",       # pop %rcx; shl(%rcx) *%rsp
  0x53 => bin"59 48d3o074o044 N",       # pop %rcx; sar(%rcx) *%rsp
  0x54 => bin"59 48d3o054o044 N",       # pop %rcx; shr(%rcx) *%rsp
  0x55 => bin"59 4821o014o044 N",       # pop %rcx; and %rcx, *%rsp
  0x56 => bin"59 4809o014o044 N",       # pop %rcx; or %rcx, *%rsp
  0x57 => bin"59 4831o014o044 N",       # pop %rcx; xor %rcx, *%rsp

  0x58 => bin"595a                      # pop %rcx, %rdx
              31o333                    # xor %ebx, %ebx
              483bo312                  # cmp %rcx to %rdx
              0f9co303                  # setl %bl
              53 N                      # push %rbx",

  0x59 => bin"595a                      # pop %rcx, %rdx
              31o333                    # xor %ebx, %ebx
              4885o312                  # testq %rcx, %rdx
              0f94o303                  # sete %bl
              53 N                      # push %rbx",

  0x5a => bin"48f7o024o044 N",          # inv *%rsp
  0x5b => bin"48f7o034o044 N",          # neg *%rsp

  0x5c => bin"59 86o351 51 N",          # pop %rcx; xchg %cl, %ch; push %rcx
  0x5d => bin"59   0fc9 51 N",          # pop %rcx; bswap %ecx; push %rcx
  0x5e => bin"59 480fc9 51 N";          # pop %rcx; bswap %rcx; push %rcx


=head3 Interpreter dispatch table
Now we have enough stuff to assemble the interpreter dispatch table and store
that address into C<%rdi> at bootup. I'm using some invalid instructions for
debugging here.
=cut

our $dispatch = "";
our @heap     = \$dispatch;
our $heap_ptr = 0x400878;

for (0..255)
{
  if (defined bytecodes->[$_])
  {
    push @heap, \bytecodes->[$_];
    $dispatch .= pack Q => $heap_ptr;
    $heap_ptr += length bytecodes->[$_];
  }
  else
  {
    $dispatch .= pack Q => $_;
  }
}


our $elf_header = pack(C16SSL => 0x7f, ord"E", ord"L", ord"F", 2, 1, 1, 0,
                       0, 0, 0, 0, 0, 0, 0, 0,
                       2, 62, 1)
                . pack(Q => $heap_ptr)
                . pack(QQLSSSSSS => 64, 0, 0, 64, 56, 1, 0, 0, 0)
                . pack(LLQQQQQQ  => 1, 7, 0,
                                    0x400000, 0, 0x1000, 0x1000, 0x1000);

our $entry_code = bin"
  48bf 78004000 00000000                # initialize %rdi
  48be # TODO
  N
";

unshift @heap, \$elf_header;
die "heap size mismatch"
  unless $heap_ptr - 0x400000 == sum map length($$_), @heap;

print join"", map $$_, @heap unless caller;


1;
